{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af939159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import expit\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6b58aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(842,)\n",
      "(842, 5)\n"
     ]
    }
   ],
   "source": [
    "pratt = pd.read_csv(\"Pratt/Pratt.csv\")\n",
    "y = pratt.choose.to_numpy()\n",
    "\n",
    "x_cols = pratt.columns[~pratt.columns.isin([\"choose\"])]\n",
    "X = pratt[x_cols].to_numpy()\n",
    "X = np.c_[np.ones(X.shape[0]), X] # add intercept\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f995fe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 286.  ,  545.5 , 4574.75, 5652.  , -489.5 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logit_score_fn(beta: np.ndarray, y: np.ndarray, X: np.ndarray): \n",
    "    \"\"\"The derivative of the log-likelihood function for a binary \n",
    "    logit model. \n",
    "\n",
    "    $$\\\\sum_{i=1}^n (y_i - 1) + 1 / (1 + \\\\exp(-beta^T * x_i))) x_i $$\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    beta: np.ndarray (k X 1)\n",
    "        parameter array to optimize over\n",
    " \n",
    "    y: np.ndarray (n X 1)  \n",
    "        array of outcomes \n",
    "\n",
    "    X: np.ndarray (n X k)\n",
    "        array of explanatory variables\n",
    "    \"\"\"\n",
    "    # temporary varialbe to hold the value of -B^T * x\n",
    "    nu = X @ beta \n",
    "    p = 1 / (1 + np.exp(-nu))\n",
    "\n",
    "    return X.T @ (y - p) \n",
    "\n",
    "\n",
    "beta_0 = np.repeat(0, X.shape[1])\n",
    "logit_score_fn(beta_0, y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26adee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: coef = -1.2217718822913008\n",
      "cars: coef = 2.308279763065528\n",
      "dovtt: coef = 0.062225970359342055\n",
      "divtt: coef = 0.009247957043049721\n",
      "dcost: coef = 0.01694424853458004\n"
     ]
    }
   ],
   "source": [
    "sol = opt.root(lambda beta: logit_score_fn(beta, y, X), beta_0)\n",
    "beta = sol.x\n",
    "\n",
    "colnames = [\"Intercept\", *x_cols]\n",
    "for col, est in zip(colnames, beta): \n",
    "    print(f\"{col}: coef = {est}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4639836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   842</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   837</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 05 Nov 2025</td> <th>  Pseudo R-squ.:     </th>  <td>0.3852</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:23:26</td>     <th>  Log-Likelihood:    </th> <td> -227.87</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -370.67</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.385e-60</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.2218</td> <td>    0.304</td> <td>   -4.025</td> <td> 0.000</td> <td>   -1.817</td> <td>   -0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.3083</td> <td>    0.226</td> <td>   10.207</td> <td> 0.000</td> <td>    1.865</td> <td>    2.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0622</td> <td>    0.019</td> <td>    3.320</td> <td> 0.001</td> <td>    0.025</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0092</td> <td>    0.009</td> <td>    0.978</td> <td> 0.328</td> <td>   -0.009</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0169</td> <td>    0.004</td> <td>    4.440</td> <td> 0.000</td> <td>    0.009</td> <td>    0.024</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &      842    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      837    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}            & Wed, 05 Nov 2025 & \\textbf{  Pseudo R-squ.:     } &   0.3852    \\\\\n",
       "\\textbf{Time:}            &     18:23:26     & \\textbf{  Log-Likelihood:    } &   -227.87   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -370.67   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 1.385e-60   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -1.2218  &        0.304     &    -4.025  &         0.000        &       -1.817    &       -0.627     \\\\\n",
       "\\textbf{x1}    &       2.3083  &        0.226     &    10.207  &         0.000        &        1.865    &        2.752     \\\\\n",
       "\\textbf{x2}    &       0.0622  &        0.019     &     3.320  &         0.001        &        0.025    &        0.099     \\\\\n",
       "\\textbf{x3}    &       0.0092  &        0.009     &     0.978  &         0.328        &       -0.009    &        0.028     \\\\\n",
       "\\textbf{x4}    &       0.0169  &        0.004     &     4.440  &         0.000        &        0.009    &        0.024     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  842\n",
       "Model:                          Logit   Df Residuals:                      837\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Wed, 05 Nov 2025   Pseudo R-squ.:                  0.3852\n",
       "Time:                        18:23:26   Log-Likelihood:                -227.87\n",
       "converged:                       True   LL-Null:                       -370.67\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.385e-60\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.2218      0.304     -4.025      0.000      -1.817      -0.627\n",
       "x1             2.3083      0.226     10.207      0.000       1.865       2.752\n",
       "x2             0.0622      0.019      3.320      0.001       0.025       0.099\n",
       "x3             0.0092      0.009      0.978      0.328      -0.009       0.028\n",
       "x4             0.0169      0.004      4.440      0.000       0.009       0.024\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(y, X)\n",
    "result = model.fit(disp=False)\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f0fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_score_by_obs(beta, y, X):\n",
    "    \"\"\"Calculates the logit score for each observation individually\"\"\"\n",
    "    p = expit(X @ beta)\n",
    "    s = (y - p)[:, None] * X\n",
    "    return s\n",
    "\n",
    "\n",
    "def hessian_logit(beta, X): \n",
    "    \"\"\"Negative empirical hessian of the binary logit model.\"\"\"\n",
    "    p = expit(X @ beta)\n",
    "    W = np.diag(p * (1 - p))\n",
    "    A_hat = X.T @ W @ X\n",
    "\n",
    "    return A_hat \n",
    "\n",
    "\n",
    "s = logit_score_by_obs(beta, y, X)\n",
    "\n",
    "B_hat = (s.T @ s)\n",
    "A_hat = hessian_logit(beta, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41914f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outer Product Form</th>\n",
       "      <th>Hessian</th>\n",
       "      <th>Sandwich</th>\n",
       "      <th>Expected Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345240</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>0.281102</td>\n",
       "      <td>0.303520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204950</td>\n",
       "      <td>0.226141</td>\n",
       "      <td>0.255106</td>\n",
       "      <td>0.226141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019246</td>\n",
       "      <td>0.018741</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.018741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outer Product Form   Hessian  Sandwich  Expected Information\n",
       "0            0.345240  0.303520  0.281102              0.303520\n",
       "1            0.204950  0.226141  0.255106              0.226141\n",
       "2            0.019246  0.018741  0.018834              0.018741\n",
       "3            0.012983  0.009458  0.006949              0.009458\n",
       "4            0.004443  0.003817  0.003306              0.003817"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ests = {\n",
    "    \"Outer Product Form\": np.sqrt(np.diag(np.linalg.inv(B_hat))),\n",
    "    \"Hessian\": np.sqrt(np.diag(np.linalg.inv(A_hat))),\n",
    "    \"Sandwich\": np.sqrt(\n",
    "        np.diag(\n",
    "            np.linalg.inv(A_hat) @ B_hat @ np.linalg.inv(A_hat)\n",
    "        )\n",
    "    ), \n",
    "    \"Expected Information\": np.sqrt(np.diag(np.linalg.inv(A_hat)))\n",
    "\n",
    "}\n",
    "\n",
    "pd.DataFrame(var_ests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcd793",
   "metadata": {},
   "source": [
    "# Parts C) and D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c085aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_OVTT estimate = 0.2723\n",
      "SE (Delta, expected info) = 0.1206\n",
      "95% CI = (0.0359, 0.5087)\n"
     ]
    }
   ],
   "source": [
    "# from inspection\n",
    "idx_cost = 4 \n",
    "idx_ovtt = 2 \n",
    "\n",
    "beta_cost = beta[idx_cost]\n",
    "beta_ovtt = beta[idx_ovtt]\n",
    "\n",
    "Vhat = beta[idx_cost] / beta[idx_ovtt]\n",
    "\n",
    "var_cost  = np.linalg.inv(A_hat)[idx_cost, idx_cost]\n",
    "var_ovtt  = np.linalg.inv(A_hat)[idx_ovtt, idx_ovtt]\n",
    "cov_cost_ovtt = np.linalg.inv(A_hat)[idx_cost, idx_ovtt]\n",
    "\n",
    "var_Vhat = (\n",
    "    (var_cost / beta_ovtt**2)\n",
    "    + (beta_cost**2 * var_ovtt / beta_ovtt**4)\n",
    "    - (2 * beta_cost * cov_cost_ovtt / beta_ovtt**3)\n",
    ")\n",
    "\n",
    "se_Vhat = np.sqrt(var_Vhat)\n",
    "\n",
    "# 95% CI\n",
    "ci_lower = Vhat - 1.96 * se_Vhat\n",
    "ci_upper = Vhat + 1.96 * se_Vhat\n",
    "\n",
    "print(f\"V_OVTT estimate = {Vhat:.4f}\")\n",
    "print(f\"SE (Delta, expected info) = {se_Vhat:.4f}\")\n",
    "print(f\"95% CI = ({ci_lower:.4f}, {ci_upper:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
